@article{rle-paper-old,
    author = {Mahankali, Srinath V. and Hong, Zhang-Wei and Sekhari, Ayush and Rakhlin, Alexander and Agrawal, Pulkit},
    title = {Random Latent Exploration for Deep Reinforcement Learning (OLD VERSION)},
    year = {2024},
    url = {https://openreview.net/forum?id=Y9qzwNlKVU}
}

@article{rle-paper,
    author = {Mahankali, Srinath V. and Hong, Zhang-Wei and Sekhari, Ayush and Rakhlin, Alexander and Agrawal, Pulkit},
    title = {Random Latent Exploration for Deep Reinforcement Learning (NEW VERSION)},
    journal = {Forty-first International Conference on Machine Learning},
    year = {2024},
    url = {https://srinathm1359.github.io/random-latent-exploration/},
    doi = {10.48550/arXiv.2407.13755}
}

@article{ppo-paper,
    author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
    title = {Proximal Policy Optimization Algorithms},
    journal = {},
    year = {2017},
    doi = {10.48550/arXiv.1707.06347}
}

@article{noisynet-paper,
    author = {Fortunato, Meire and Azar, Mohammad G. and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier and Blundell, Charles and Legg, Shane},
    title = {Noisy Networks for Exploration},
    journal = {International Conference on Machine Learning},
    year = {2018},
    doi = {10.48550/arXiv.1706.10295}
}

@article{rnd-paper,
    author = {Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
    title = {Exploration by Random Network Distillation},
    journal = {International Conference on Learning Representations},
    year = {2019},
    url = {https://openreview.net/forum?id=H1lJJnR5Ym}
}


@article{grid-world-paper,
	author = {Richard S. Sutton and Doina Precup and Satinder Singh},
	journal = {Artificial Intelligence},
	number = {1},
	pages = {181-211},
	title = {Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370299000521},
	volume = {112},
	year = {1999}
}


@article{shannon-entropy-paper,
	author = {Shannon, C. E.},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	journal = {The Bell System Technical Journal},
	number = {3},
	pages = {379-423},
	title = {A mathematical theory of communication},
	volume = {27},
	year = {1948}
}


@misc{gymnasium-paper,
	archiveprefix = {arXiv},
	author = {Mark Towers and Ariel Kwiatkowski and Jordan Terry and John U. Balis and Gianluca De Cola and Tristan Deleu and Manuel Goul{\~a}o and Andreas Kallinteris and Markus Krimmel and Arjun KG and Rodrigo Perez-Vicente and Andrea Pierr{\'e} and Sander Schulhoff and Jun Jet Tai and Hannah Tan and Omar G. Younis},
	eprint = {2407.17032},
	title = {Gymnasium: A Standard Interface for Reinforcement Learning Environments},
	url = {https://arxiv.org/abs/2407.17032},
	year = {2024},
}


@misc{generalized-advantage-estimation-paper,
	author = {John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
	title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
	url = {https://arxiv.org/abs/1506.02438},
	year = {2018}
}


@unpublished{von-mises-fisher-paper,
	author = {Pinz{\'o}n, Carlos and Jung, Kangsoo},
	month = Aug,
	note = {working paper or preprint},
	pdf = {https://hal.science/hal-04004568v3/file/main.pdf},
	title = {{Fast Python sampler for the von Mises Fisher distribution}},
	url = {https://hal.science/hal-04004568},
	year = {2023},
}

@article{agent57,
    author = {Badia, Adrià Puigdomènech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Blundell, Charles },
	title = {Agent57: Outperforming the Atari Human Benchmark},
    year = {2020},
    url = {https://arxiv.org/abs/2003.13350},
	doi = {10.48550/arXiv.2003.13350}
}

@article{atari-introduction,
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	title = {Playing Atari with Deep Reinforcement Learning},
    year = {2013},
    url = {https://arxiv.org/abs/1312.5602},
	doi = {10.48550/arXiv.1312.5602}
}


@article{clearnrl-paper,
	author = {Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga and Dipam Chakraborty and Kinal Mehta and Jo{\~a}o G.M. Ara{\'u}jo},
	journal = {Journal of Machine Learning Research},
	number = {274},
	pages = {1--18},
	title = {CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
	url = {http://jmlr.org/papers/v23/21-1342.html},
	volume = {23},
	year = {2022},
}

@mastersthesis{ppo-description-paper,
  author  = {Bick, Daniel},
  title   = {Towards Delivering a Coherent Self-Contained Explanation of Proximal Policy Optimization},
  school  = {University of Groningen},
  year    = {2021},
  type    = {Master's Thesis},
  url     = {https://fse.studenttheses.ub.rug.nl/25709/}
}

@article{skrl-paper,
  author  = {Antonio Serrano-Muñoz and Dimitrios Chrysostomou and Simon Bøgh and Nestor Arana-Arexolaleiba},
  title   = {skrl: Modular and Flexible Library for Reinforcement Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {254},
  pages   = {1--9},
  url     = {http://jmlr.org/papers/v24/23-0112.html}
}